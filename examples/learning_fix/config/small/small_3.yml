preprocess:
  work_model: preprocess

  train_src: examples/learning_fix/data/small/train-buggy.txt
  train_src_path: examples/learning_fix/data/small/train-buggy-path.txt
  train_tgt: examples/learning_fix/data/small/train-fixed.txt
  train_tgt_path: examples/learning_fix/data/small/train-fixed-path.txt
  train_align: examples/learning_fix/data/small/small-train-feedward.talp

  valid_src: examples/learning_fix/data/small/eval-buggy.txt
  valid_src_path: examples/learning_fix/data/small/eval-buggy-path.txt
  valid_tgt: examples/learning_fix/data/small/eval-fixed.txt
  valid_tgt_path: examples/learning_fix/data/small/eval-fixed-path.txt
  valid_align: examples/learning_fix/data/small/small-eval-feedward.talp


  save_data: examples/learning_fix/data/small/small
  src_seq_length: 46680
  tgt_seq_length: 46680
  src_seq_length_trunc: 400
  tgt_seq_length_trunc: 200
  num_threads: 10
  overwrite: True
  share_vocab: True
  pos_vec_size: 256
  data_type: "code"

train:
  work_model: train
  data: examples/learning_fix/data/small/small
  save_checkpoint_steps: 2000
  keep_checkpoint: 1000
  seed: 3435
  train_steps: 1000000
  valid_steps: 5000
  early_stopping: 10
  warmup_steps: 4000
  report_every: 1000


  decoder_type: transformer
  encoder_type: transformer
  word_vec_size: 512
  rnn_size: 512
  layers: 6
  transformer_ff: 2048
  heads: 8

  accum_count: [4]
  accum_steps: [0]
  model_dtype: "fp32"
  optim: adam
  adam_beta1: 0.9
  adam_beta2: 0.98
  decay_method: "noam"
  learning_rate: 2
  max_grad_norm: 0

  batch_size: 2048
  batch_type: tokens
  normalization: tokens
  dropout: 0.2
  attention_dropout: [0.1]
  label_smoothing: 0.1

  max_generator_batches: 0

  param_init: 0.0
  param_init_glorot: 'true'
  position_encoding: 'true'
  path_encoding: 'true'

  lambda_align: 0.05
  alignment_layer: -1
  alignment_heads: 4
  full_context_alignment: true

  master_port: 8003
  world_size: 2
  gpu_ranks:
    - 0
    - 1
  model: examples/learning_fix/data/small/3/small-step-100000-acc-93.61-ppl-1.26-xent-0.23.pt

translate:
  work_model: translate
  src: examples/learning_fix/data/small/test-buggy.txt
  src_path: examples/learning_fix/data/small/test-buggy-path.txt
  tgt: examples/learning_fix/data/small/test-fixed.txt
  tgt_path: examples/learning_fix/data/small/test-fixed-path.txt
  data_type: "code"
  share_vocab: True
  min_length: 0
  max_length: 100
  batch_size: 16
  gpu: 0
#  report_align: 'true'
  model: examples/learning_fix/data/small/3/small-step-100000-acc-93.61-ppl-1.26-xent-0.23.pt
