preprocess:
  work_model: preprocess

  train_src: examples/sequenceR/data/baseline/src-train.txt
  train_tgt: examples/sequenceR/data/baseline/tgt-train.txt

  valid_src: examples/sequenceR/data/baseline/src-val.txt
  valid_tgt: examples/sequenceR/data/baseline/tgt-val.txt

  save_data: examples/sequenceR/data/baseline/baseline
  src_seq_length: 1010
  tgt_seq_length: 100
  src_seq_length_trunc: 400
  tgt_seq_length_trunc: 200
  src_vocab_size: 1000
  tgt_vocab_size: 1000
  dynamic_dict: True
  num_threads: 10
  overwrite: True
  share_vocab: True
  pos_vec_size: 256
  data_type: "code"

train:
  work_model: train
  data: examples/sequenceR/data/baseline/baseline
  save_checkpoint_steps: 2000
  keep_checkpoint: 1000
  seed: 3435
  train_steps: 50000
  valid_steps: 5000
  early_stopping: 10
  warmup_steps: 4000
  report_every: 1000
  batch_size: 256

  encoder_type: brnn
  enc_layers: 2
  decoder_type: rnn
  dec_layers: 2
  rnn_size: 256
  global_attention: general

  word_vec_size: 256
  bridge: True
  copy_attn: True
  reuse_copy_attn: True

  master_port: 8001
  world_size: 4
  gpu_ranks:
    - 0
    - 1
    - 2
    - 3

translate:
  work_model: translate
  model: examples/sequenceR/data/baseline/1/small-step-36000-acc-97.56-ppl-1.10-xent-0.09.pt
  src: examples/sequenceR/data/baseline/test-buggy.txt
  src_path: examples/sequenceR/data/baseline/test-buggy-path.txt
  tgt: examples/sequenceR/data/baseline/test-fixed.txt
  tgt_path: examples/sequenceR/data/baseline/test-fixed-path.txt
  data_type: "code"
  share_vocab: True
  min_length: 0
  max_length: 100
  batch_size: 16
  gpu: 0
#  report_align: 'true'
