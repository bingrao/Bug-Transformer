train:
  app: 'bug2fix'
  work_model: train
  do_train: true
  do_eval: true
  model_type: "roberta"
  model_name_or_path: /home/bing/project/Bug-Transformer/examples/codebert/data/codebert-base
  train_filename:
    - /home/bing/project/Bug-Transformer/examples/learning_fix/data/small/train-buggy-src.txt
    - /home/bing/project/Bug-Transformer/examples/learning_fix/data/small/train-fixed-src.txt

  dev_filename:
    - /home/bing/project/Bug-Transformer/examples/learning_fix/data/small/eval-buggy-src.txt
    - /home/bing/project/Bug-Transformer/examples/learning_fix/data/small/eval-fixed-src.txt

  learning_rate: 5e-5
  train_batch_size: 4
  eval_batch_size: 4
  beam_size: 5
  max_source_length: 510
  max_target_length: 510
  eval_steps: 1000  # 400 for ruby, 600 for javascript, 1000 for others
  train_steps: 50000  # 20000 for ruby, 30000 for javascript, 50000 for others
  local_rank: 1

translate:
  app: 'bug2fix'
  work_model: translate